from google.adk.apps.app import App, EventsCompactionConfig
from google.adk.agents import LlmAgent
from google.adk.sessions import InMemorySessionService
from google.adk.runners import Runner
from google.adk.apps.llm_event_summarizer import LlmEventSummarizer
from google.adk.models import Gemini, Content, LlmRequest
from google.adk.agents.callback_context import CallbackContext
from typing import List, Optional
from google.adk.events import Event, EventActions

# Lightweight LLM for summaries
summarizer_llm = Gemini(model="gemini-2.5-flash")

class FirstPreservingSummarizer(LlmEventSummarizer):
    """
    Custom summarizer: Skips the first event (preserves it raw) and summarizes only middle events in the window.
    Assumes first event is identified via session.state['first_event'].
    """
    async def _summarize_events_async(self, events: List[Event], session_id: str) -> Event:
        # Fetch full session events (ADK summarizer has access via session_id; use session_service if injected)
        from google.adk.sessions import SessionId  # Assume session_service is global or injected
        session = session_service.get_session(SessionId(session_id))  # Replace with your session_service
        full_events = session.events if session else events

        # Get first event from state (set on session init)
        first_event = session.state.get('first_event') if session else full_events[0] if full_events else None

        # Filter window: Exclude first if present; summarize only non-last-3 (but since window is older, last-3 are future)
        filtered_events = []
        for event in events:
            if event.id == first_event.id if first_event else event == full_events[0]:
                continue  # Skip firstâ€”preserve raw elsewhere
            filtered_events.append(event)

        if not filtered_events:
            return Event(content=Content.text("No middle events to summarize."), actions=EventActions.compaction)

        # Parent's summarization logic (customize prompt for middles)
        summary_prompt = self._build_prompt(filtered_events)  # Use parent's template, but focused on middles
        summary_response = await self.llm.generate_content_async([Content.text(summary_prompt)])
        summary_text = summary_response.text

        return Event(
            content=Content.text(f"Middle conversation summary: {summary_text}"),
            actions=EventActions.compaction
        )

# Instantiate
custom_summarizer = FirstPreservingSummarizer(llm=summarizer_llm)

# Compaction config
compaction_config = EventsCompactionConfig(
    compaction_interval=15,  # Trigger after 15 events (adjust for session length)
    overlap_size=3,          # Retain last 3 from prior window in next summary for continuity
    summarizer=custom_summarizer
)

# Your agent
root_agent = LlmAgent(
    name="my_agent",
    model="gemini-2.0-flash-exp",
    instruction="You are a helpful assistant. Use the provided history: first message + middle summary + last 3 exchanges."
)

app = App(
    name="selective-retention-app",
    root_agent=root_agent,
    events_compaction_config=compaction_config
)

session_service = InMemorySessionService()
runner = Runner(app=app, session_service=session_service)
