# project structure:
# .
# ├── app.py                # Main Streamlit app
# ├── utils.py              # Utility functions for extraction, aggregation, etc.
# ├── llm_insights.py       # LLM-related functions
# ├── report_generator.py   # PDF report generation
# └── requirements.txt      # Dependencies

# --- utils.py ---
import pdfplumber
from pptx import Presentation
import numpy as np
from PIL import Image
import io
import re
import json
import pandas as pd
import streamlit as st  # For warnings in utils if needed

def extract_from_pdf_page_by_page(file_content):
    """Extract text, tables, and OCR from images page by page in PDF."""
    pages_content = []
    try:
        with pdfplumber.open(file_content) as pdf:
            for page_num, page in enumerate(pdf.pages, start=1):
                text = page.extract_text() or ""
                tables = [pd.DataFrame(t) for t in page.extract_tables() if t]
                images_text = ""
                try:
                    import easyocr
                    reader = easyocr.Reader(['en'])
                    for img in page.images:
                        try:
                            img_bytes = page.get_image(img['stream']).as_bytes()
                            img_pil = Image.open(io.BytesIO(img_bytes))
                            ocr_result = reader.readtext(np.array(img_pil))
                            images_text += " ".join([res[1] for res in ocr_result]) + "\n"
                        except Exception:
                            pass
                except ImportError:
                    st.warning("easyocr not available; skipping OCR.")
                except Exception as e:
                    st.warning(f"OCR failed: {e}; skipping OCR.")
                page_content = f"Page {page_num}:\n{text}\n{images_text}"
                pages_content.append((page_content, tables))
    except Exception as e:
        st.error(f"PDF processing failed: {e}")
        pages_content = []
    return pages_content

def extract_from_pptx_slide_by_slide(file_content):
    """Extract text and tables slide by slide in PPTX."""
    pages_content = []
    try:
        prs = Presentation(file_content)
        for slide_num, slide in enumerate(prs.slides, start=1):
            text = ""
            tables = []
            for shape in slide.shapes:
                if shape.has_text_frame:
                    for paragraph in shape.text_frame.paragraphs:
                        for run in paragraph.runs:
                            text += run.text + " "
                if shape.has_table:
                    table_data = [[cell.text for cell in row.cells] for row in shape.table.rows]
                    if table_data:
                        tables.append(pd.DataFrame(table_data))
            page_content = f"Slide {slide_num}:\n{text}"
            pages_content.append((page_content, tables))
    except Exception as e:
        st.error(f"PPTX processing failed: {e}")
        pages_content = []
    return pages_content

def process_document_page_by_page(file, file_type):
    """Process PDF or PPTX page/slide by page."""
    file.seek(0)  # Reset file pointer
    file_content = io.BytesIO(file.read())
    if file_type == 'pdf':
        return extract_from_pdf_page_by_page(file_content)
    elif file_type == 'pptx':
        return extract_from_pptx_slide_by_slide(file_content)
    else:
        raise ValueError("Unsupported file type")

def aggregate_insights(pages_insights):
    """Aggregate page insights into document-level sections."""
    aggregated = {
        'objectives': [],
        'architecture': [],
        'integrations': [],
        'performance': [],
        'costs': [],
        'other': []
    }
    for insight in pages_insights:
        if isinstance(insight, dict) and "error" not in insight:
            for key in aggregated:
                val = insight.get(key)
                if val:
                    if isinstance(val, list):
                        aggregated[key].extend([str(v) for v in val])
                    else:
                        aggregated[key].append(str(val))
    for key in aggregated:
        aggregated[key] = " ".join(aggregated[key]) if aggregated[key] else ""
    return aggregated

# --- llm_insights.py ---
import openai
import json
import re

try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        # Improved extraction: Handle ```json, ```, or raw JSON; fallback if no match
        if '```' in content:
            match = re.search(r'```(?:json)?\s*(.*?)\s*```', content, re.DOTALL)
            if match:
                content = match.group(1).strip()
            else:
                # Fallback: strip markdown-like wrappers if present
                content = content.strip()
        else:
            content = content.strip()
        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            return {"error": f"JSON parsing failed: {e}", "raw": content}
    except Exception as e:
        return {"error": f"LLM call failed: {e}"}

def get_llm_comparison(client, doc1_agg, doc2_agg):
    """Use OpenAI LLM for comprehensive comparison using aggregated insights with JSON mode."""
    prompt = f"""
    Compare these two application designs based on aggregated insights:

    Document 1 Aggregated:
    {json.dumps(doc1_agg)}

    Document 2 Aggregated:
    {json.dumps(doc2_agg)}

    Provide a structured JSON response only. Do not add any text outside the JSON object:
    {{
        "relevance": {{"score": 85, "explanation": "Explanation here"}},
        "reusable_components": ["List with details"],
        "architecture_design": "Similarities/differences.",
        "integration_possibilities": "Opportunities/challenges.",
        "performance": "Comparison.",
        "other_insights": "Timelines, costs, recommendations."
    }}
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        # Extract JSON if wrapped
        if "```json" in content:
            content = re.search(r'```json
        return json.loads(content)
    except json.JSONDecodeError as e:
        return {"error": f"JSON parsing failed: {e}", "raw": response.choices[0].message.content if 'response' in locals() else "No response"}
    except Exception as e:
        return {"error": f"LLM call failed: {e}"}

def get_llm_single_analysis(client, doc_agg):
    """Use OpenAI LLM for single document analysis using aggregated insights with JSON mode."""
    prompt = f"""
    Analyze this application design document based on aggregated insights:

    Document Aggregated:
    {json.dumps(doc_agg)}

    Provide a structured JSON response only. Do not add any text outside the JSON object:
    {{
        "summary": "Overall summary of the document.",
        "reusable_components": ["List of potential reusable elements (e.g., modules, agents)"],
        "architecture_design": "Description of the architecture.",
        "integration_possibilities": "Potential integrations with other systems.",
        "other_insights": "Additional insights like timelines, costs, benefits, recommendations."
    }}
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        content = response.choices[0].message.content
        # Extract JSON if wrapped
        if "```json" in content:
            content = re.search(r'```json
        return json.loads(content)
    except json.JSONDecodeError as e:
        return {"error": f"JSON parsing failed: {e}", "raw": response.choices[0].message.content if 'response' in locals() else "No response"}
    except Exception as e:
        return {"error": f"LLM call failed: {e}"}

# --- report_generator.py ---
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from io import BytesIO

def generate_pdf_report(insights, doc_name, is_comparison=False, doc2_name=None):
    """Generate a PDF report using ReportLab for single or comparison."""
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    styles = getSampleStyleSheet()
    elements = []

    # Title
    if is_comparison:
        title = f"Document Comparison Report: {doc_name} vs {doc2_name}"
    else:
        title = f"Document Analysis Report: {doc_name}"
    elements.append(Paragraph(title, styles['Title']))
    elements.append(Spacer(1, 12))

    # Sections
    if is_comparison:
        sections = [
            ("Relevance", insights.get('relevance', {})),
            ("Reusable Components", insights.get('reusable_components', 'N/A')),
            ("Architecture Design", insights.get('architecture_design', 'N/A')),
            ("Integration Possibilities", insights.get('integration_possibilities', 'N/A')),
            ("Performance Comparison", insights.get('performance', 'N/A')),
            ("Other Insights", insights.get('other_insights', 'N/A'))
        ]
    else:
        sections = [
            ("Summary", insights.get('summary', 'N/A')),
            ("Reusable Components", insights.get('reusable_components', 'N/A')),
            ("Architecture Design", insights.get('architecture_design', 'N/A')),
            ("Integration Possibilities", insights.get('integration_possibilities', 'N/A')),
            ("Other Insights", insights.get('other_insights', 'N/A'))
        ]

    for title, content in sections:
        elements.append(Paragraph(title, styles['Heading2']))
        if isinstance(content, dict):
            if 'score' in content:
                elements.append(Paragraph(f"Score: {content['score']}", styles['Normal']))
            if 'explanation' in content:
                elements.append(Paragraph(content['explanation'], styles['Normal']))
        elif isinstance(content, list):
            for item in content:
                elements.append(Paragraph(f"- {item}", styles['Normal']))
        else:
            elements.append(Paragraph(str(content), styles['Normal']))
        elements.append(Spacer(1, 12))

    doc.build(elements)
    buffer.seek(0)
    return buffer

# --- app.py ---
import streamlit as st
import openai
from utils import process_document_page_by_page, aggregate_insights
from llm_insights import get_llm_page_insight, get_llm_comparison, get_llm_single_analysis
from report_generator import generate_pdf_report

st.title("Document Analysis and Comparison Tool")

# OpenAI API Key
api_key = st.text_input("Enter your OpenAI API Key", type="password")
if not api_key:
    st.warning("Please enter your OpenAI API Key.")
    st.stop()
client = openai.OpenAI(api_key=api_key)

# Upload files
doc1 = st.file_uploader("Upload Document 1 (PDF or PPTX)", type=['pdf', 'pptx'])
doc2 = st.file_uploader("Upload Document 2 (PDF or PPTX, optional for comparison)", type=['pdf', 'pptx'])

# Review button
if st.button("Review Documents"):
    if not doc1:
        st.error("Please upload Document 1.")
        st.stop()
    
    doc1_type = doc1.name.split('.')[-1]
    doc1_name = doc1.name
    
    try:
        with st.spinner("Analyzing Document 1 page by page..."):
            doc1_pages = process_document_page_by_page(doc1, doc1_type)
            if not doc1_pages:
                st.error("No content extracted from Document 1. Check file format.")
                st.stop()
            doc1_insights = []
            for page_content, _ in doc1_pages:
                if page_content.strip():  # Skip empty pages
                    insight = get_llm_page_insight(client, page_content)
                    doc1_insights.append(insight)
            doc1_agg = aggregate_insights(doc1_insights)
    except Exception as e:
        st.error(f"Error processing Document 1: {e}")
        st.stop()
    
    if doc2:
        doc2_type = doc2.name.split('.')[-1]
        doc2_name = doc2.name
        
        try:
            with st.spinner("Analyzing Document 2 page by page..."):
                doc2_pages = process_document_page_by_page(doc2, doc2_type)
                if not doc2_pages:
                    st.error("No content extracted from Document 2. Check file format.")
                    st.stop()
                doc2_insights = []
                for page_content, _ in doc2_pages:
                    if page_content.strip():
                        insight = get_llm_page_insight(client, page_content)
                        doc2_insights.append(insight)
                doc2_agg = aggregate_insights(doc2_insights)
        except Exception as e:
            st.error(f"Error processing Document 2: {e}")
            st.stop()
        
        with st.spinner("Generating Comparison..."):
            analysis = get_llm_comparison(client, doc1_agg, doc2_agg)
        
        is_comparison = True
        report_title = "Comparison Report"
    else:
        with st.spinner("Generating Single Document Analysis..."):
            analysis = get_llm_single_analysis(client, doc1_agg)
        
        is_comparison = False
        report_title = "Analysis Report"
        doc2_name = None
    
    # Display Results
    st.header(report_title)
    if "error" in analysis:
        st.error(analysis["error"])
        if "raw" in analysis:
            st.write(analysis["raw"])
    else:
        if is_comparison:
            st.markdown("### Relevance")
            rel = analysis.get('relevance', {})
            st.markdown(f"**Score:** {rel.get('score', 'N/A')}")
            st.markdown(rel.get('explanation', 'N/A'))
            
            st.markdown("### Reusable Components")
            for comp in analysis.get('reusable_components', []):
                st.markdown(f"- {comp}")
            
            st.markdown("### Architecture Design")
            st.markdown(analysis.get('architecture_design', 'N/A'))
            
            st.markdown("### Integration Possibilities")
            st.markdown(analysis.get('integration_possibilities', 'N/A'))
            
            st.markdown("### Performance Comparison")
            st.markdown(analysis.get('performance', 'N/A'))
            
            st.markdown("### Other Insights")
            st.markdown(analysis.get('other_insights', 'N/A'))
        else:
            st.markdown("### Summary")
            st.markdown(analysis.get('summary', 'N/A'))
            
            st.markdown("### Reusable Components")
            for comp in analysis.get('reusable_components', []):
                st.markdown(f"- {comp}")
            
            st.markdown("### Architecture Design")
            st.markdown(analysis.get('architecture_design', 'N/A'))
            
            st.markdown("### Integration Possibilities")
            st.markdown(analysis.get('integration_possibilities', 'N/A'))
            
            st.markdown("### Other Insights")
            st.markdown(analysis.get('other_insights', 'N/A'))
    
    # PDF Download
    try:
        pdf_buffer = generate_pdf_report(analysis, doc1_name, is_comparison, doc2_name)
        st.download_button(
            label="Download PDF Report",
            data=pdf_buffer,
            file_name="document_report.pdf",
            mime="application/pdf"
        )
    except Exception as e:
        st.error(f"PDF generation failed: {e}")

# --- requirements.txt ---
streamlit
pdfplumber
python-pptx
openai
pandas
numpy
pillow
easyocr
reportlab
